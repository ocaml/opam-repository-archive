opam-version: "2.0"
maintainer: "unixjunkie@sdf.org"
authors: "Francois Berenger"
license: "LGPL-2.0-or-later"
homepage: "https://github.com/UnixJunkie/parany"
bug-reports: "https://github.com/UnixJunkie/parany/issues"
dev-repo: "git+https://github.com/UnixJunkie/parany.git"
depends: [
  "ocaml" {>= "4.03.0"}
  "dune" {< "2.0"}
  "base-unix" {= "base"}
  "ocamlnet" {<= "4.1.9-2"}
]
build: [
  ["dune" "build" "-p" name]
  ["dune" "runtest" "-p" name] {with-test}
]
synopsis: "Parallelize any computation"
description: """
Generalized map reduce for parallel computers (not distributed computing).
Can process in parallel an infinite stream of elements.

Can process a very large file in parallel on a multicore computer;
provided there is a way to cut your file into independent blocks
(the 'demux' function).
The processing function is called 'work'.
The function gathering the results is called 'mux'.
The number of processors running your computation in parallel is called
'nprocs'.
The chunk size (number of items) processed by one call to the 'work' function
is called 'csize'.

Read the corresponding ocamldoc before using.
"""
url {
  src: "https://github.com/UnixJunkie/parany/archive/v5.0.1.tar.gz"
  checksum: [
    "md5=62c54d0940df3b0236fdef5721100958"
    "sha512=026af6ebdc82b9d384046fe833c0e7c12dbbff416ece1be24b2941ffef9716e089cba31b49b8f8c6da1bc72ce108992b52480733c163d975eb7d46e3859bd451"
  ]
}
x-opam-repository-commit-hash-at-time-of-archiving:
  "08d8c16c16dc6b23a5278b06dff0ac6c7a217356"
x-reason-for-archiving: ["maintenance-intent"]
